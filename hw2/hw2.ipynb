{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73287530-1a9f-42d9-8cb5-5e27d9bfc482",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pypIn this homework, we will use the Diabetes dataset. (Note: You can use the built-in function from ML libraries for gradient descent, training, and validation.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cae1c54-963e-4d24-9247-8ac89cb8126a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.134</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>543</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>125</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.6</td>\n",
       "      <td>0.191</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>168</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.537</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>139</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>1.441</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>60</td>\n",
       "      <td>23</td>\n",
       "      <td>846</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.398</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>166</td>\n",
       "      <td>72</td>\n",
       "      <td>19</td>\n",
       "      <td>175</td>\n",
       "      <td>25.8</td>\n",
       "      <td>0.587</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.484</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>84</td>\n",
       "      <td>47</td>\n",
       "      <td>230</td>\n",
       "      <td>45.8</td>\n",
       "      <td>0.551</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>107</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.254</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>83</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.183</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>70</td>\n",
       "      <td>30</td>\n",
       "      <td>96</td>\n",
       "      <td>34.6</td>\n",
       "      <td>0.529</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0             6      148             72             35        0  33.6   \n",
       "1             1       85             66             29        0  26.6   \n",
       "2             8      183             64              0        0  23.3   \n",
       "3             1       89             66             23       94  28.1   \n",
       "4             0      137             40             35      168  43.1   \n",
       "5             5      116             74              0        0  25.6   \n",
       "6             3       78             50             32       88  31.0   \n",
       "7            10      115              0              0        0  35.3   \n",
       "8             2      197             70             45      543  30.5   \n",
       "9             8      125             96              0        0   0.0   \n",
       "10            4      110             92              0        0  37.6   \n",
       "11           10      168             74              0        0  38.0   \n",
       "12           10      139             80              0        0  27.1   \n",
       "13            1      189             60             23      846  30.1   \n",
       "14            5      166             72             19      175  25.8   \n",
       "15            7      100              0              0        0  30.0   \n",
       "16            0      118             84             47      230  45.8   \n",
       "17            7      107             74              0        0  29.6   \n",
       "18            1      103             30             38       83  43.3   \n",
       "19            1      115             70             30       96  34.6   \n",
       "\n",
       "    DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                      0.627   50        1  \n",
       "1                      0.351   31        0  \n",
       "2                      0.672   32        1  \n",
       "3                      0.167   21        0  \n",
       "4                      2.288   33        1  \n",
       "5                      0.201   30        0  \n",
       "6                      0.248   26        1  \n",
       "7                      0.134   29        0  \n",
       "8                      0.158   53        1  \n",
       "9                      0.232   54        1  \n",
       "10                     0.191   30        0  \n",
       "11                     0.537   34        1  \n",
       "12                     1.441   57        0  \n",
       "13                     0.398   59        1  \n",
       "14                     0.587   51        1  \n",
       "15                     0.484   32        1  \n",
       "16                     0.551   31        1  \n",
       "17                     0.254   31        1  \n",
       "18                     0.183   33        0  \n",
       "19                     0.529   32        1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv('diabetes.csv')\n",
    "dataset.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00d059f2-171f-4a30-a5f6-576e9730b2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.000e+00, 1.480e+02, 7.200e+01, 3.500e+01, 0.000e+00, 3.360e+01,\n",
       "        6.270e-01, 5.000e+01],\n",
       "       [1.000e+00, 8.500e+01, 6.600e+01, 2.900e+01, 0.000e+00, 2.660e+01,\n",
       "        3.510e-01, 3.100e+01],\n",
       "       [8.000e+00, 1.830e+02, 6.400e+01, 0.000e+00, 0.000e+00, 2.330e+01,\n",
       "        6.720e-01, 3.200e+01],\n",
       "       [1.000e+00, 8.900e+01, 6.600e+01, 2.300e+01, 9.400e+01, 2.810e+01,\n",
       "        1.670e-01, 2.100e+01],\n",
       "       [0.000e+00, 1.370e+02, 4.000e+01, 3.500e+01, 1.680e+02, 4.310e+01,\n",
       "        2.288e+00, 3.300e+01],\n",
       "       [5.000e+00, 1.160e+02, 7.400e+01, 0.000e+00, 0.000e+00, 2.560e+01,\n",
       "        2.010e-01, 3.000e+01],\n",
       "       [3.000e+00, 7.800e+01, 5.000e+01, 3.200e+01, 8.800e+01, 3.100e+01,\n",
       "        2.480e-01, 2.600e+01],\n",
       "       [1.000e+01, 1.150e+02, 0.000e+00, 0.000e+00, 0.000e+00, 3.530e+01,\n",
       "        1.340e-01, 2.900e+01],\n",
       "       [2.000e+00, 1.970e+02, 7.000e+01, 4.500e+01, 5.430e+02, 3.050e+01,\n",
       "        1.580e-01, 5.300e+01],\n",
       "       [8.000e+00, 1.250e+02, 9.600e+01, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        2.320e-01, 5.400e+01],\n",
       "       [4.000e+00, 1.100e+02, 9.200e+01, 0.000e+00, 0.000e+00, 3.760e+01,\n",
       "        1.910e-01, 3.000e+01],\n",
       "       [1.000e+01, 1.680e+02, 7.400e+01, 0.000e+00, 0.000e+00, 3.800e+01,\n",
       "        5.370e-01, 3.400e+01],\n",
       "       [1.000e+01, 1.390e+02, 8.000e+01, 0.000e+00, 0.000e+00, 2.710e+01,\n",
       "        1.441e+00, 5.700e+01],\n",
       "       [1.000e+00, 1.890e+02, 6.000e+01, 2.300e+01, 8.460e+02, 3.010e+01,\n",
       "        3.980e-01, 5.900e+01],\n",
       "       [5.000e+00, 1.660e+02, 7.200e+01, 1.900e+01, 1.750e+02, 2.580e+01,\n",
       "        5.870e-01, 5.100e+01],\n",
       "       [7.000e+00, 1.000e+02, 0.000e+00, 0.000e+00, 0.000e+00, 3.000e+01,\n",
       "        4.840e-01, 3.200e+01],\n",
       "       [0.000e+00, 1.180e+02, 8.400e+01, 4.700e+01, 2.300e+02, 4.580e+01,\n",
       "        5.510e-01, 3.100e+01],\n",
       "       [7.000e+00, 1.070e+02, 7.400e+01, 0.000e+00, 0.000e+00, 2.960e+01,\n",
       "        2.540e-01, 3.100e+01],\n",
       "       [1.000e+00, 1.030e+02, 3.000e+01, 3.800e+01, 8.300e+01, 4.330e+01,\n",
       "        1.830e-01, 3.300e+01],\n",
       "       [1.000e+00, 1.150e+02, 7.000e+01, 3.000e+01, 9.600e+01, 3.460e+01,\n",
       "        5.290e-01, 3.200e+01]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset.iloc[:, [0,1,2,3,4,5,6,7]].values\n",
    "Y = dataset.iloc[:, 8].values\n",
    "X[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272e901f-7746-4589-b645-fa7c9b2f5322",
   "metadata": {},
   "source": [
    "# Problem 1 (30 points)\n",
    "Using the diabetes dataset, build a logistic regression binary classifier for positive diabetes. Please use 80% and 20% split between training and evaluation (test). Make sure to perform proper scaling and standardization before your training. Report your results, including accuracy, precision, and recall. Also, plot the confusion matrix representing your binary classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4f25306-7777-46cd-933a-e8dcd3ad7441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,train_size=0.8, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3c90061-2e6f-4794-a971-447a8b65d84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scalling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4e1e9dd-3707-469a-8a56-9e170d7120e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logistic regression from sklearn.linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state=0)\n",
    "classifier.fit (X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22ea1f5a-cda0-4e22-9ad5-1419ac46065b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = classifier.predict(X_test)\n",
    "Y_pred[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faa5a61a-a9b3-451c-afb4-dab092ecc925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[89, 10],\n",
       "       [24, 31]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cnf_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aed4535d-f477-4ba8-b073-74e02c23415f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7792207792207793\n",
      "Precision: 0.7560975609756098\n",
      "Recall: 0.5636363636363636\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, Y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(Y_test, Y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0faef023-ce9e-4a24-bcfd-e6f3ff56212e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 257.44, 'Predicted label')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "class_names=[0,1] # name of classes\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "\n",
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346f41a9-f3de-4a5f-83a6-de4c3a3212c8",
   "metadata": {},
   "source": [
    "# Problem 2 (30 points)\n",
    "Using the diabetes dataset, build a Na√Øve Bays binary classifier for positive diabetes. Please use 80% and 20% split between training and evaluation (test). Make sure to perform proper scaling and standardization before your training. Report your results, including accuracy, precision, and recall. Also, plot the confusion matrix representing your binary classifier. Compare and analyze your results against problem 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f5691c0-8671-4d6f-bbfd-c9e799e7344d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2711f59c-db01-4afd-957f-f8dbf4b0585e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 2 features per sample; expecting 8",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b03fac2dd07d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max()),\n\u001b[1;32m      4\u001b[0m                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max()))\n\u001b[0;32m----> 5\u001b[0;31m plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X), \n\u001b[0m\u001b[1;32m      6\u001b[0m              alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \"\"\"\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0m\u001b[1;32m    289\u001b[0m                              % (X.shape[1], n_features))\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: X has 2 features per sample; expecting 8"
     ]
    }
   ],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "X_set, Y_set = X_test, Y_test\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, \n",
    "                               stop = X_set[:, 0].max()\n",
    "                              ),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, \n",
    "                               stop = X_set[:, 1].max()\n",
    "                              )\n",
    "                    )\n",
    "plt.contourf(X1, X2, \n",
    "             classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X), \n",
    "             alpha = 0.75, \n",
    "             cmap = ListedColormap(('red', 'green'))\n",
    "            )\n",
    "\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "             \n",
    "for i, j in enumerate(np.unique(Y_set)):\n",
    "    plt.scatter(X_set[Y_set == j, 0], X_set[Y_set == j, 1],\n",
    "        c = ListedColormap(('yellow', 'blue'))(i), label = j)\n",
    "             \n",
    "plt.title('Logistic Regression (Test set)')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Estimated Salary')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdda708-95e4-48f4-a29a-a672cb183e94",
   "metadata": {},
   "source": [
    "# Problem 3 (30 points)\n",
    "Repeat problem 1, and this time use K-fold cross-validation for your training and validation. Perform the training two times for K=5 and K=10. Analyze and compare your results against problem 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a648e4b6-01d3-4e8b-a7b6-6b06a61e2688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86c88c33-71e7-4508-b0e9-c842c3776596",
   "metadata": {},
   "source": [
    "# Problem 4 (10 points)\n",
    "Repeat problem 2, and this time use K-fold cross-validation for your training and validation. Does this make sense? Elaborate on your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81df4bc2-4557-4c40-a8af-1877eb775b23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
